---
title: "Identificación de Patrones ocultos de Desarrollo Internacional Mediante Técnicas de Aprendizaje No Supervisado: "
subtitle: "Un Estudio con Datos del Banco Mundial 2022"
author: "Barros Rayo Alejandro (2415837), Muñoz Portela Diego Fernando (2415620), Portilla Aguirre Johan Camilo (2422468)"
date: "`r format(Sys.Date(), '%d de %B de %Y')`"
---

# Introducción

La capacidad de anticipar el comportamiento futuro de los precios en los mercados financieros constituye uno de los elementos centrales para la toma de decisiones de inversión estratégicas y la gestión eficiente de portafolios. En el contexto de los mercados bursátiles globales, donde la incertidumbre es inherente y los patrones de precios reflejan complejas dinámicas de oferta y demanda, el desarrollo de modelos predictivos robustos cobra particular relevancia para inversionistas, analistas financieros y gestores de cartera.

El Invesco QQQ Trust (QQQ) es uno de los fondos cotizados en bolsa (ETF) más negociados a nivel mundial, con activos bajo gestión superiores a los 400 mil millones de dólares. Este instrumento replica el índice Nasdaq-100, compuesto por las 100 empresas no financieras de mayor capitalización bursátil listadas en el mercado Nasdaq, con una fuerte concentración en el sector tecnológico que incluye líderes como Apple, Microsoft, NVIDIA, Amazon y Alphabet. Entre 2009 y 2019, el QQQ se benefició significativamente de las economías de escala en software, el auge de los smartphones y el desarrollo de ecosistemas tecnológicos integrados. Esta composición convierte al QQQ en un referente para analizar el comportamiento del sector tecnológico estadounidense y, por extensión, las tendencias de innovación que impulsan la economía global.

La importancia de modelar series de precios como la del QQQ radica en múltiples factores. En primer lugar, los pronósticos financieros juegan un papel fundamental en la formación de expectativas de mercado e influyen directamente en las decisiones de inversión, la asignación de activos y la evaluación de riesgos. En segundo lugar, el análisis cuantitativo de series temporales permite identificar patrones y comportamientos que proporcionan información valiosa para diseñar estrategias de inversión más fundamentadas. La predicción específica del QQQ es particularmente importante porque replica el índice Nasdaq-100, concentrado en empresas tecnológicas líderes en desarrollo de inteligencia artificial, computación en la nube y ecosistemas digitales innovadores. Dado que el sector tecnológico representa uno de los mercados emergentes y con mayor potencial de crecimiento en la economía global, predecir el comportamiento del QQQ permite anticipar tendencias en innovación, evaluar correctamente la valuación de activos tecnológicos y gestionar la exposición al riesgo en un sector de alta volatilidad que impulsa transformaciones estructurales en la economía mundial.

En este contexto, los modelos ARIMA (AutoRegressive Integrated Moving Average) se han consolidado como uno de los enfoques más utilizados para el pronóstico de series de tiempo, junto con los modelos de suavizado exponencial. Mientras que los modelos de suavizado exponencial se basan en una descripción de la tendencia y la estacionalidad en los datos, los modelos ARIMA tienen como objetivo describir las autocorrelaciones presentes en la serie. Estos modelos integran tres componentes fundamentales: el componente autorregresivo (AR), que pronostica la variable de interés utilizando una combinación lineal de sus valores pasados; el componente de integración (I), que transforma series no estacionarias en estacionarias mediante la aplicación de diferencias sucesivas; y el componente de media móvil (MA), que utiliza errores de pronóstico pasados en un modelo similar a la regresión.

Un aspecto fundamental previo al ajuste de modelos ARIMA es la verificación de la estacionariedad de la serie temporal. Una serie estacionaria es aquella cuyas propiedades no dependen del momento en que se observa; es decir, presenta media aproximadamente horizontal, varianza constante y no muestra patrones predecibles a largo plazo. Las series temporales con tendencias o estacionalidad no son estacionarias. Para identificar series no estacionarias, se emplean tanto herramientas gráficas (la función de autocorrelación ACF de datos no estacionarios decrece lentamente) como pruebas estadísticas formales, entre las que destaca el Test Aumentado de Dickey-Fuller, cuya hipótesis nula establece que los datos son no estacionarios.

El presente estudio emplea datos históricos del ETF QQQ obtenidos de Yahoo Finance, abarcando el período comprendido entre el 7 de octubre de 2022 y el 2 de diciembre de 2025, con un total de 791 observaciones diarias de precios de cierre. Durante este período, el precio del QQQ fluctuó entre un mínimo de \$260.10 y un máximo de \$635.77, con un precio promedio de \$435.84 y una desviación estándar de \$97.95. El rendimiento acumulado del período alcanzó un notable 131.14%, reflejando la fuerte recuperación del sector tecnológico tras el mercado bajista de 2022 y el impulso generado por desarrollos en inteligencia artificial. La volatilidad anualizada de la serie se ubicó en aproximadamente 21.12%, característica de instrumentos con alta exposición al sector tecnológico.

El análisis incluye la verificación de supuestos estadísticos fundamentales: evaluación de estacionariedad mediante la prueba de Dickey-Fuller Aumentada y análisis gráfico de las funciones de autocorrelación (ACF) y autocorrelación parcial (PACF), la selección del modelo óptimo utilizando criterios de información (AICc), y la validación diagnóstica de residuos para confirmar que se comporten como ruido blanco. Se comparan múltiples especificaciones ARIMA, incluyendo el modelo seleccionado automáticamente mediante la función auto.arima y configuraciones alternativas sugeridas por el análisis de los gráficos ACF y PACF, reconociendo que aunque la automatización es útil, "cualquier cosa automatizada puede ser un poco peligrosa, y vale la pena entender algo sobre el comportamiento de los modelos".

------------------------------------------------------------------------

# Metodología

La metodología adoptada sigue el procedimiento estándar de modelamiento de series temporales propuesto en la literatura: se particiona el conjunto de datos en un conjunto de entrenamiento (746 observaciones, hasta el 30 de septiembre de 2025) para ajustar y validar diferentes especificaciones ARIMA, y un conjunto de prueba (45 observaciones, desde octubre de 2025) para evaluar la capacidad predictiva de los modelos fuera de muestra. Este diseño experimental permite contrastar las predicciones generadas con valores reales observados, proporcionando métricas objetivas sobre la precisión del pronóstico.

## Base de datos

La base de datos utilizada en este análisis proviene de Yahoo Finance, una de las plataformas más reconocidas y utilizadas a nivel mundial para la obtención de datos financieros históricos de acciones, índices bursátiles y fondos cotizados en bolsa (ETF). Yahoo Finance proporciona información de precios de cierre, apertura, máximos, mínimos y volúmenes de negociación con frecuencia diaria, garantizando accesibilidad, confiabilidad y cobertura temporal extensa para el análisis de series de tiempo financieras.

Para este análisis, se empleó el ETF Invesco QQQ Trust (símbolo: QQQ), el cual replica el índice Nasdaq-100 y está compuesto por las 100 empresas no financieras de mayor capitalización listadas en el mercado Nasdaq. La extracción de datos se realizó mediante la función `getSymbols()` del paquete `quantmod` de R, que permite automatizar la descarga directa desde la fuente. El período de estudio abarca desde el 7 de octubre de 2022 hasta el 2 de diciembre de 2025, resultando en un total de 791 observaciones diarias de precios de cierre.

El período seleccionado es particularmente informativo para el análisis de series temporales financieras, ya que captura la recuperación del sector tecnológico tras el mercado bajista de 2022, el impulso generado por los desarrollos en inteligencia artificial, y las fluctuaciones asociadas a cambios en las políticas monetarias de la Reserva Federal.

## Descripción de las variables

El dataset construido para este análisis se centra en una única variable cuantitativa: el precio de cierre diario del ETF QQQ. Esta variable representa el último precio al que se negoció el instrumento durante cada sesión bursátil y es la medida estándar utilizada en el análisis técnico y la modelización de series temporales financieras.

La elección del precio de cierre como variable de análisis se fundamenta en que este refleja el consenso del mercado al finalizar cada sesión, incorporando toda la información disponible durante el día de negociación. Además, es el precio utilizado para el cálculo de rendimientos, valoración de portafolios y la mayoría de los indicadores técnicos.

## Partición de datos

En el análisis de series temporales, es práctica estándar dividir los datos disponibles en subconjuntos separados para entrenar y validar el modelo. La partición temporal es fundamental para evaluar la capacidad predictiva de un modelo en un escenario realista.

La estrategia de partición temporal respeta el orden cronológico de los datos, dividiendo la serie en un conjunto de entrenamiento que comprende la mayor parte de las observaciones históricas, utilizado para identificar los parámetros óptimos del modelo y estimar sus coeficientes, y un conjunto de prueba que representa un período posterior no utilizado durante el ajuste, permitiendo evaluar cómo habría funcionado el modelo en un escenario de pronóstico real.

Esta metodología es esencial en series temporales porque evita la "fuga de información" (data leakage) que ocurriría si se permitiera que datos futuros influyeran en la predicción del pasado. A diferencia de la validación cruzada aleatoria utilizada en otros contextos, la partición secuencial mantiene la estructura cronológica de los datos, respetando las dependencias temporales inherentes a estos.

## Descripción del modelo

El presente estudio adopta la metodología de modelos ARIMA (AutoRegressive Integrated Moving Average), desarrollada por Box y Jenkins en la década de 1970, la cual proporciona un marco sistemático y robusto para el análisis y pronóstico de series temporales. Los modelos ARIMA se fundamentan en la idea de que el valor actual de una serie puede explicarse mediante una función de sus valores pasados, sus errores de pronóstico pasados, o una combinación de ambos elementos.

A diferencia de los modelos de regresión tradicionales que requieren variables explicativas externas, los modelos ARIMA son modelos univariados que extraen toda la información predictiva de la propia historia de la serie. Esta característica los hace especialmente útiles cuando no se dispone de predictores externos confiables o cuando el objetivo es capturar la dinámica intrínseca de la serie temporal.

La filosofía subyacente de los modelos ARIMA es que las series temporales exhiben patrones de autocorrelación, es decir, correlación entre observaciones separadas por diferentes intervalos de tiempo (rezagos o lags). Este modelo a su vez captura estas autocorrelaciones de manera parsimoniosa mediante la combinación de tres componentes que trabajan de forma integrada.

### Componentes del modelo ARIMA(p,d,q)

La notación ARIMA(p,d,q) especifica tres parámetros que definen completamente el modelo:

-   **p (Autorregresivo):** Orden de la parte autorregresiva. Indica cuántos valores pasados de la serie se utilizan para predecir el valor actual.

-   **d (Integración):** Grado de diferenciación. Número de veces que se debe diferenciar la serie para alcanzar estacionariedad.

-   **q (Media Móvil):** Orden de la parte de media móvil. Indica cuántos errores de pronóstico pasados se incorporan al modelo.

#### Componente Autorregresivo AR(p)

El modelo autorregresivo de orden $p$ (AR(p)) pronostica la variable de interés utilizando una combinación lineal de sus valores pasados:

$$y_t = c + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \cdots + \phi_p y_{t-p} + \varepsilon_t$$

donde:

-   $y_t$ es el valor de la serie en el tiempo $t$
-   $c$ es una constante (intercepto)
-   $\phi_1, \phi_2, \ldots, \phi_p$ son los coeficientes autorregresivos que miden la influencia de cada rezago
-   $\varepsilon_t$ es el término de error (ruido blanco) con media cero y varianza constante $\sigma^2$

En un modelo AR(1), el valor actual depende únicamente del valor inmediatamente anterior. El coeficiente $\phi_1$ indica la persistencia de la serie: valores cercanos a 1 implican alta persistencia (los shocks tienen efectos duraderos), mientras que valores cercanos a 0 indican que la serie revierte rápidamente a su media. Para que el modelo sea estacionario, los coeficientes deben satisfacer restricciones específicas.

La interpretación económica del componente AR es que si una serie ha estado elevada en el período anterior, tiende a permanecer elevada en el período actual, capturando el concepto de inercia o persistencia en el comportamiento de la variable.

#### Componente de Media Móvil MA(q)

El modelo de media móvil de orden $q$ (MA(q)) utiliza errores de pronóstico pasados en lugar de valores pasados de la variable:

$$y_t = c + \varepsilon_t + \theta_1 \varepsilon_{t-1} + \theta_2 \varepsilon_{t-2} + \cdots + \theta_q \varepsilon_{t-q}$$

donde $\theta_1, \ldots, \theta_q$ son los coeficientes de media móvil.

La interpretación económica del componente MA es que los shocks o sorpresas en una serie tienen efectos transitorios que se disipan gradualmente. Esto es útil para capturar comportamientos donde los precios o valores regresan a su nivel promedio después de una perturbación, en lugar de permanecer desplazados permanentemente.

#### Componente de Integración I(d)

Muchas series temporales económicas y financieras no son estacionarias en su forma original, presentando tendencias, medias cambiantes o varianzas no constantes. Una serie estacionaria es aquella cuyas propiedades estadísticas (media, varianza, autocovarianzas) son invariantes en el tiempo, mientras que una serie no estacionaria exhibe comportamientos que dependen del momento en que se observa.

El componente de integración aborda este problema mediante la diferenciación, una transformación que calcula los cambios entre observaciones consecutivas:

$$y'_t = y_t - y_{t-1} = \Delta y_t$$

Esta operación, conocida como primera diferencia, elimina tendencias lineales y puede estabilizar la media de la serie. Si una diferencia no es suficiente para lograr estacionariedad, se puede aplicar una segunda diferencia:

$$y''_t = y'_t - y'_{t-1} = \Delta^2 y_t$$

El parámetro $d$ indica el número de diferencias necesarias para que la serie se vuelva estacionaria. Una serie que requiere $d$ diferencias para ser estacionaria se denomina integrada de orden $d$, denotada como I(d). En la práctica, rara vez se requieren más de dos diferencias.

### Formulación general del modelo ARIMA(p,d,q)

Combinando los tres componentes, el modelo ARIMA(p,d,q) se puede expresar de forma compacta utilizando el operador de rezago $B$ (donde $B y_t = y_{t-1}$):

$$\Phi(B)(1-B)^d y_t = c + \Theta(B) \varepsilon_t$$

donde:

-   $\Phi(B) = 1 - \phi_1 B - \phi_2 B^2 - \cdots - \phi_p B^p$ es el polinomio autorregresivo
-   $(1-B)^d$ es el operador de diferenciación aplicado $d$ veces
-   $\Theta(B) = 1 + \theta_1 B + \theta_2 B^2 + \cdots + \theta_q B^q$ es el polinomio de media móvil

Esta representación compacta facilita el análisis teórico del modelo y la derivación de sus propiedades estadísticas. La elegancia de esta formulación radica en que captura dinámicas complejas mediante la combinación sistemática de componentes que actúan en diferentes niveles: el componente AR modela la persistencia, el componente MA modela los efectos de shocks transitorios, y el componente I transforma la serie para alcanzar propiedades estadísticas deseables.

### Supuestos del modelo

Para que las inferencias estadísticas y los pronósticos derivados del modelo ARIMA sean válidos y confiables, es necesario que se cumplan ciertos supuestos fundamentales sobre la naturaleza de la serie y sus residuos. Estos supuestos garantizan que el modelo captura adecuadamente la estructura de los datos y que las propiedades estadísticas del modelo son robustas.

En primer lugar, la serie temporal debe presentar estacionariedad en media y varianza, lo que significa que sus propiedades estadísticas permanecen aproximadamente constantes a lo largo del tiempo. Esto es crítico porque asegura que las relaciones identificadas entre observaciones son estables y predecibles, en lugar de ser resultado de tendencias determinísticas no modeladas.

En segundo lugar, los residuos del modelo ajustado deben comportarse como ruido blanco, es decir, como una secuencia de observaciones aleatorias e independientes sin patrones sistemáticos. Si los residuos contienen estructura, esto sugiere que el modelo no ha capturado completamente la dinámica temporal de los datos.

Adicionalmente, se asume que los errores son homoscedásticos, teniendo varianza constante a través del tiempo. Finalmente, aunque no es estrictamente necesario para la estimación del modelo, la normalidad de los residuos es deseable para la construcción de intervalos de confianza precisos y para la validez de las pruebas de hipótesis sobre los parámetros.

## Herramientas conceptuales para la identificación y validación del modelo

### Pruebas de estacionariedad

La estacionariedad es un requisito previo fundamental antes de proceder con la modelización ARIMA. Una serie no estacionaria produciría inferencias engañosas y pronósticos poco confiables. Por ello, se requieren métodos formales para evaluar si una serie posee esta propiedad o necesita transformaciones.

La **Prueba Aumentada de Dickey-Fuller (ADF)** es el contraste estadístico estándar en la práctica. Esta prueba contrasta la hipótesis nula de presencia de una raíz unitaria (indicador de no estacionariedad) contra la alternativa de que la serie es estacionaria. El resultado de esta prueba determina el orden de integración $d$ del modelo ARIMA: si la serie original falla la prueba, se procede a diferenciar y repetir hasta lograr estacionariedad.

### Funciones de autocorrelación: ACF y PACF

Las funciones de autocorrelación proporcionan una ventana diagnóstica para entender patrones de dependencia temporal en los datos. Son herramientas esenciales en la identificación preliminar de la estructura ARIMA.

**Función de Autocorrelación (ACF):** Cuantifica la correlación entre observaciones de la serie separadas por diferentes rezagos. Su comportamiento es diagnóstico: en series estacionarias decae gradualmente hacia cero, mientras que en series no estacionarias persiste en valores altos durante muchos rezagos. Desde la perspectiva de identificación del modelo, el ACF es particularmente útil para distinguir procesos de media móvil: un corte abrupto después del rezago $q$ sugiere un componente MA(q).

**Función de Autocorrelación Parcial (PACF):** Elimina la influencia de rezagos intermedios, aislando el efecto directo de cada rezago sobre el presente. Esta función es especialmente informativa para identificar procesos autorregresivos: un corte abrupto después del rezago $p$ sugiere un componente AR(p).

El análisis combinado de estos gráficos proporciona indicios valiosos sobre la especificación inicial del modelo, aunque debe complementarse con criterios estadísticos formales.

### Búsqueda automática: función auto.arima

En la práctica moderna, la función `auto.arima()` automatiza gran parte del proceso de identificación del modelo mediante algoritmos de búsqueda. Esta función realiza una búsqueda sistemática sobre un rango especificado de valores para $p$, $d$ y $q$, evaluando cada combinación mediante criterios de información como AICc.

Sin embargo, es importante reconocer que aunque la automatización es conveniente, conlleva limitaciones. Un modelo automatizado puede omitir especificaciones que, aunque menos óptimas según criterios puramente estadísticos, podrían ser preferibles bajo consideraciones teóricas o interpretativas. Por esta razón, resulta valioso complementar la búsqueda automática con el análisis visual de ACF y PACF, permitiendo que la teoría económica y el conocimiento del dominio del problema informen la especificación final.

### Criterios de selección del modelo: AICc

Cuando múltiples especificaciones ARIMA son candidatas, es necesario un criterio objetivo para elegir entre ellas. Los **criterios de información** cumplen este rol al balancear la calidad del ajuste con la complejidad del modelo.

El **AICc (Criterio de Información de Akaike Corregido)** es el criterio más utilizado en la práctica para la selección de modelos ARIMA. Este criterio evalúa la verosimilitud del modelo (qué tan bien se ajusta a los datos) y aplica una penalización por agregar parámetros adicionales, reduciendo la tendencia al sobreajuste. Su fórmula es:

$$\text{AICc} = \text{AIC} + \frac{2(p+q+k+1)(p+q+k+2)}{T-p-q-k-2}$$

donde $T$ es el número de observaciones, $p$ y $q$ son los órdenes del modelo ARIMA, y $k$ es el número de parámetros adicionales (como la constante). El término adicional respecto al AIC clásico corrige el sesgo que ocurre en muestras pequeñas.

Especificaciones con menor AICc son preferibles, ya que indican un mejor balance entre ajuste y parsimonia. Un aspecto crítico es que los criterios de información no son aplicables para seleccionar el orden de diferenciación $d$, pues la diferenciación altera la escala de los datos sobre la cual se computa la verosimilitud, haciendo que los valores de AICc no sean comparables entre modelos con diferente $d$. Por ello, el parámetro $d$ se determina primero mediante pruebas de estacionariedad, y el AICc se utiliza posteriormente para optimizar los órdenes $p$ y $q$.

### Diagnóstico de residuos: Prueba de Ljung-Box

Después de ajustar un modelo ARIMA específico, es necesario verificar que el modelo haya capturado adecuadamente la estructura temporal. El diagnóstico de residuos es el procedimiento mediante el cual se evalúa esta adecuación.

La **Prueba de Ljung-Box** es un contraste estadístico que evalúa si existe autocorrelación significativa en los residuos. Contrasta la hipótesis nula de ausencia de autocorrelación contra la alternativa de presencia de autocorrelación en al menos algún rezago. Si los residuos conservan autocorrelación, es señal de que el modelo especificado no ha extraído completamente la información temporal disponible, requiriendo respecificación con órdenes más altos.

Un p-valor elevado en esta prueba indica que los residuos se comportan consistentemente con ruido blanco, suministrando confianza en que el modelo ha cumplido su propósito de modelar adecuadamente la dinámica temporal de la serie.

### Criterios de selección del modelo

Cuando múltiples especificaciones ARIMA son candidatas, es necesario un criterio objetivo para elegir entre ellas. Los **criterios de información** como el AICc cumplen este rol al balancear la calidad del ajuste con la complejidad del modelo.

El AICc penaliza la inclusión de parámetros adicionales, previniendo el sobreajuste que podría resultar en pronósticos pobres fuera de muestra. Especificaciones con menor AICc son preferibles. Un aspecto crítico es que estos criterios no son aplicables para seleccionar el orden de diferenciación $d$, pues la diferenciación altera la escala sobre la cual se computa la verosimilitud. Por ello, $d$ se determina primero mediante pruebas de estacionariedad, y el AICc se utiliza posteriormente para optimizar $p$ y $q$.

## Procedimiento metodológico general

La metodología Box-Jenkins, desarrollada como framework estándar para la modelización ARIMA, propone un proceso iterativo:

1.  **Determinación del orden de integración:** Se evalúa estacionariedad mediante pruebas formales, identificando el número de diferencias necesarias.

2.  **Análisis exploratorio de ACF y PACF:** Se examinan los gráficos de autocorrelación para obtener sugerencias preliminares sobre órdenes $p$ y $q$.

3.  **Estimación comparativa:** Se ajustan múltiples especificaciones candidatas, comparándolas según criterios de información. La búsqueda automática puede iniciar este proceso, pero debe complementarse con especificaciones alternativas sugeridas por el análisis gráfico.

4.  **Validación diagnóstica:** Se examinan los residuos del modelo seleccionado mediante análisis gráfico y pruebas estadísticas, verificando que se asemejen a ruido blanco.

5.  **Generación de pronósticos:** Una vez validado el modelo, se procede a realizar predicciones sobre el conjunto de datos de prueba.

## Métricas de evaluación del desempeño predictivo

Para evaluar objetivamente la precisión de los pronósticos generados por el modelo ARIMA en el conjunto de prueba, se emplean métricas cuantitativas estándar:

**RMSE (Root Mean Squared Error):** $$\text{RMSE} = \sqrt{\frac{1}{n} \sum_{t=1}^{n} (\hat{y}_t - y_t)^2}$$

Esta métrica amplifica penalizaciones sobre errores grandes, siendo sensible a presencia de valores atípicos en los errores de pronóstico.

**MAE (Mean Absolute Error):** $$\text{MAE} = \frac{1}{n} \sum_{t=1}^{n} |\hat{y}_t - y_t|$$

Proporciona una medida de error promedio que es menos sensible a outliers que el RMSE, ofreciendo una perspectiva más robusta del desempeño general.

**MAPE (Mean Absolute Percentage Error):** $$\text{MAPE} = \frac{100}{n} \sum_{t=1}^{n} \left| \frac{y_t - \hat{y}_t}{y_t} \right|$$

Expresa el error como porcentaje relativo del valor observado, permitiendo comparabilidad del desempeño independientemente de la magnitud absoluta de los valores predichos.
